### Trim/merge tools have default parameters for min_length and min_overlap


### Set global variables

PROJECTDIR = "/home/projects2/DNA_reconstruct/PCA_population_analysis_publication"
INDIR = PROJECTDIR + "/input"

SEED = 2718
SUBSAMPLE_SEEDS = list(range(1, 11))
SUBSAMPLE_FRACTIONS = ["06", "12", "24", "48", "96"] # for 0.25X, 0.5X, 1X, 2X, 4X coverage depth 

TOOLNAMES = ["AdapterRemoval", "leeHom", "ClipAndMerge", "seqtk_adna_trim", "bbmerge", "fastp", "SeqPrep"]
SAMPLES = ["HG002", "HG005"]


ORIG_READ_LEN = 250
REF_GENOME = INDIR + "/ref_genome/hs37d5.fa"
FRAGLEN = "Vi33.19_max250.txt" 

pos = INDIR + "/human_origins_genotype_dataset/data.pos"
snp = INDIR + "/human_origins_genotype_dataset/data.snp"

OUTDIR = PROJECTDIR + "/output"
OUTDIR_BEN = OUTDIR + "/benchmarks"
OUTDIR_TRIM = OUTDIR + "/initial_trim"
OUTDIR_SIM = OUTDIR + "/simulations"
OUTDIR_REC = OUTDIR + "/reconstructions"
OUTDIR_ALI = OUTDIR + "/alignment"
OUTDIR_EIG = OUTDIR + "/eigenstrat"
OUTDIR_VAR = OUTDIR + "/variants"
OUTDIR_EVA = OUTDIR + "/evaluation"
OUTDIR_PLOT = OUTDIR + "/plots"



# tools
FRAGSIM = "/home/ctools/gargammel/src/fragSim"
ADPTSIM = "/home/ctools/gargammel/src/adptSim"
ART = "/home/ctools/gargammel/art_src_MountRainier_Linux/art_illumina"
#LEEHOM = "/home/ctools/leeHom-1.2.15/src/leeHom"
LEEHOM = "/home/projects/gabriel/leehom_interweaved/leeHom" 
ADPTREM = "/home/ctools/adapterremoval-2.3.2/build/AdapterRemoval"
CLIPMERGE = "/home/ctools/ClipAndMerge-1.7.8/build/libs/ClipAndMerge-1.7.8.jar"
SEQTK = "/home/ctools/seqtk-1.3/seqtk"
ADNA = "/home/ctools/adna/adna-trim"
BBMERGE = "/home/ctools/bbmap_38_91/bbmerge.sh"
FASTP = "/home/ctools/fastp/fastp"
SEQPREP = "/home/ctools/SeqPrep-1.3.2/SeqPrep"
BWA = "/home/ctools/bwa-0.7.17/bwa"
PICARD = "/home/ctools/picard_2.27.5/picard.jar" 
GATK = "/home/ctools/gatk-4.2.1.0/gatk"
samtools = "/home/ctools/samtools-1.13/samtools"
# scripts
EVAL_SCRIPT = PROJECTDIR + "/evaluate.py"
MERGE_SCRIPT = PROJECTDIR + "/merge_csv.sh"
PLOT_SCRIPT = PROJECTDIR + "/plot.py"

# Input adapter sequences
ADPT1 = "AGATCGGAAGAGCACACGTCTGAACTCCAGTCACCGATTCGATCTCGTATGCCGTCTTCTGCTTG"
ADPT2 = "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTCGCCGTATCATTT"


### Run all
rule all:
    input:
        # Coverages
        expand(OUTDIR_ALI + "/{tool_name}/{sample}_markdup_coverage.tsv",
            tool_name=TOOLNAMES,
            sample=SAMPLES,
            ),
        OUTDIR_PLOT + "/pca_explained_variance_individual.png",
    # run:
    #     shell("gzip {OUTDIR_SIM}/*")


### Get modern DNA fragments of length 250

rule filter_reads:
    """
    Discard all reads with adapter sequences: Min length must be equal to 
    read length. Perfrom quality control on the filtered reads.
    """
    input:
        INDIR + "/illumina_forward_reads/{sample}.fastq.gz",
    output:
        o=OUTDIR_TRIM + "/{sample}_filtered.fq.gz",
    params:
        basename=OUTDIR_TRIM + "/{sample}",
    run:
        shell(
            "{ADPTREM}"
            " --file1 {input}"
            " --output1 {output.o}"
            " --basename {params.basename}"
            " --minlength {ORIG_READ_LEN}"
            " --threads 7"
        )
        shell(
           "rm {params.basename}.discarded {params.basename}.settings"
        )


rule fastqc:
    input:
        OUTDIR_TRIM + "/{sample}.fq",
    output:
        OUTDIR_TRIM + "/fastqc/{sample}_fastqc.html",
        OUTDIR_TRIM + "/fastqc/{sample}_fastqc.zip",
    params:
        outdir=OUTDIR_TRIM + "/fastqc",
    shell:
        (
            "fastqc -o {params.outdir} {input}"
        )
    

### Fragment DNA and simulate Illumina paired-end reads

rule simulate_fragments:
    """
    gargammel fragSim:
    simulation of ancient DNA fragments being retrieved at random from 
    the genome.
    """
    input:
        OUTDIR_TRIM + "/{sample}_filtered.fq",
    output:
        OUTDIR_SIM + "/{sample}_frag.fa",
    params:
        fraglen=INDIR + "/insert_lengths/" + FRAGLEN,
    shell:
        (
            "{FRAGSIM}"
            " --fq"
            " -s {params.fraglen}"
            " {input}"
            " | seqkit fq2fa"
            " > {output}" 
            )


rule add_adapters:
    """
    gargammel adptSim:
    adding adapters to create raw Illumina reads (without errors and
    quality scores)

    Output reads as ART (unzipped fasta) with wrap-around for paired-end
    mode.
    """
    input:
        OUTDIR_SIM + "/{sample}_frag.fa", 
    output:
        OUTDIR_SIM + "/{sample}_adpt.fa",
    shell:
        # -l        : Desired read length
        # -artp     : Output reads as ART with wrap-around
        (
            "{ADPTSIM}" 
            " -l 125"
            " -artp {output}"
            " {input}"
        )


rule simulate_reads:
    """
    add sequencing errors and corresponding quality scores
    Illumina HiSeq 2500 (125bp, 150bp)
    """
    input:
        OUTDIR_SIM + "/{sample}_adpt.fa",
    output:
        OUTDIR_SIM + "/{sample}_s1.fq",
        OUTDIR_SIM + "/{sample}_s2.fq",
    params:
        out_prefix=OUTDIR_SIM + "/{sample}_s",
    shell:
        # --insRate     : insertion rate
        # -dr           : deletion rate
        # --seqSys      : HS25: Illumina HiSeq 2500
        # --len         : read length
        # --rcount      : number of read pairs to be generated per sequence
        # --paired      : paired-end read simulation
        # --amplicon    : amplicon sequencing simulation
        # --noALN       : do not output ALN alignment file
        # --quiet       : turn off end of run summary
        # --rndSeed     : the seed for random number generator, use a
        #                 fixed seed to generate two identical datasets
        #                 from different runs
        (
            "{ART}"
            " --insRate 0"
            " --insRate2 0"
            " -dr 0"
            " -dr2 0"
            " --seqSys HS25"
            " --len 125"
            " --rcount 1"
            " --paired"
            " --amplicon"
            " --noALN"
            " --quiet"
            " --rndSeed {SEED}"
            " -i {input}"
            " -o {params.out_prefix}"
        )


# rule zip_sim_files:
#     input:
#         OUTDIR_SIM + "/{filename}",
#     output:
#         OUTDIR_SIM + "/{filename}.gz",
#     shell:
#         ("gzip {input}")


### Trim and merge with each tool 


rule leeHom:
    """Reconstruction using leeHom"""
    input:
        s1=OUTDIR_SIM + "/{sample}_s1.fq.gz",
        s2=OUTDIR_SIM + "/{sample}_s2.fq.gz",
    output:
        OUTDIR_REC + "/leeHom/{sample}_merged.fq.gz",
    params:
        out_prefix=OUTDIR_REC + "/leeHom/{sample}_merged",
        rm1=OUTDIR_REC + "/leeHom/{sample}_merged_r1.fq.gz",
        rm2=OUTDIR_REC + "/leeHom/{sample}_merged_r2.fq.gz",
        rm3=OUTDIR_REC + "/leeHom/{sample}_merged.fail.fq.gz",
        rm4=OUTDIR_REC + "/leeHom/{sample}_merged_r1.fail.fq.gz",
        rm5=OUTDIR_REC + "/leeHom/{sample}_merged_r2.fail.fq.gz",
    benchmark:
        OUTDIR_BEN + "/leeHom/{sample}_merged.tsv"
    run:
        shell(
            "{LEEHOM}"
            " --ancientdna"
            " --adapterFirstRead {ADPT1}"
            " --adapterSecondRead {ADPT2}"
            " -fq1 {input.s1}"
            " -fq2 {input.s2}"
            " -fqo {params.out_prefix}"
        )
        shell(
            "rm"
            " {params.rm1}"
            " {params.rm2}"
            " {params.rm3}"
            " {params.rm4}"
            " {params.rm5}"
        )


rule AdapterRemoval:
    """Reconstruction using AdapterRemoval"""
    input:
        s1=OUTDIR_SIM + "/{sample}_s1.fq.gz",
        s2=OUTDIR_SIM + "/{sample}_s2.fq.gz",
    output:
        OUTDIR_REC + "/AdapterRemoval/{sample}_merged.fq.gz",
    params:
        merged=OUTDIR_REC + "/AdapterRemoval/{sample}_merged.fq.gz",
        basename=OUTDIR_REC + "/AdapterRemoval/{sample}_unmerged",
    benchmark:
        OUTDIR_BEN + "/AdapterRemoval/{sample}_merged.tsv"
    run:
        # --minlength LENGTH
        #     Reads shorter than this length are discarded following trimming
        #     [default: 15].
        # --minalignmentlength LENGTH
        #     If --collapse is set, paired reads must overlap at least this number
        #     of bases to be collapsed, and single-ended reads must overlap at
        #     least this number of bases with the adapter to be considered complete
        #     template molecules [default: 11].
        # --seed SEED
        #     Sets the RNG seed used when choosing between bases with 
        #     equal Phred scores.
        # --qualitymax BASE
        #     Specifies the maximum Phred score expected in input files, and used
        #     when writing output. ASCII encoded values are limited to the
        #     characters '!' (ASCII = 33) to '~' (ASCII = 126), meaning that
        #     possible scores are 0 - 93 with offset 33, and 0 - 62 for offset 64
        #     and Solexa scores [default: 41].
        #
        # number of threads is by default 1
        shell(
            "{ADPTREM}"
            " --gzip"
            " --collapse"
            " --qualitymax 93"
            " --adapter1 {ADPT1}"
            " --adapter2 {ADPT2}"
            " --file1 {input.s1}"
            " --file2 {input.s2}"
            " --basename {params.basename}"
            " --outputcollapsed {params.merged}"
            " --seed {SEED}"
        )
        shell(
            "rm {params.basename}*"
        )


rule ClipAndMerge:
    """Reconstruction using ClipAndMerge"""
    input:
        s1=OUTDIR_SIM + "/{sample}_s1.fq.gz",
        s2=OUTDIR_SIM + "/{sample}_s2.fq.gz",
    output:
        m=OUTDIR_REC + "/ClipAndMerge/{sample}_merged.fq.gz",
    benchmark:
        OUTDIR_BEN + "/ClipAndMerge/{sample}_merged.tsv"
    shell:
        # -l INTEGER      : Discard sequences shorter than 
        #                   this number of nucleotides after adapter 
        #                   clipping. (default: 25)
        # -p INTEGER      : Minimal number of nucleotides that have to
        #                   overlap in order to merge the forward and
        #                   reverse read. (default: 10)
        # -u FORWARD_FILE REVERSE_FILE : 
        #                   Write unmerged forward and 
        #                   reverse reads to extra files. the regular
        #                   output file then only contains merged reads!
        (
            "java -jar {CLIPMERGE}"
            " -in1 {input.s1}"
            " -in2 {input.s2}"
            " -f {ADPT1}"
            " -r {ADPT2}"
            " -o {output.m}"
            " -u /dev/null /dev/null"
        )


rule seqtk_adna_trim:
    """Reconstruction using seqtk and adna-trim"""
    input:
        s1=OUTDIR_SIM + "/{sample}_s1.fq.gz",
        s2=OUTDIR_SIM + "/{sample}_s2.fq.gz",
    output:
        OUTDIR_REC + "/seqtk_adna_trim/{sample}_merged.fq.gz",
    benchmark:
        OUTDIR_BEN + "/seqtk_adna_trim/{sample}_merged.tsv"
    shell:
        # seqtk mergepe: interleave two paired-end FASTA/Q files
        # adna-trim:
        # -l INT       min read/fragment length to output [default: 30]
        # -t INT       number of threads [default: 2]
        # -o INT       min overlap length [10]
        # -p STR       output PE reads to STR.R[12].fq.gz 
        #              [default: discard pe]
        (
            "{SEQTK} mergepe"
            " {input.s1}"
            " {input.s2} |"
            " {ADNA}"
            " -t 1"
            " -"
            " | gzip "
            " > {output}"
        )


rule bbmerge:
    """Reconstruction using BBMerge"""
    input:
        s1=OUTDIR_SIM + "/{sample}_s1.fq.gz",
        s2=OUTDIR_SIM + "/{sample}_s2.fq.gz",
    output:
        m=OUTDIR_REC + "/bbmerge/{sample}_merged.fq.gz",
    benchmark:
        OUTDIR_BEN + "/bbmerge/{sample}_merged.tsv"
    shell:
        # t=1             Set threads to 1
        # mininsert=35    Minimum insert size to merge reads.
        # mininsert0=35   Insert sizes less than this will not be considered.
        #                 Must be less than or equal to mininsert.
        # minoverlap=12   Minimum number of overlapping bases to allow merging.
        # minoverlap0=8   Overlaps shorter than this will not be considered.
        #                 Must be less than or equal to minoverlap.
        # outu=<file>   : File for unmerged reads.
        (
            "{BBMERGE}"
            " in1={input.s1}"
            " in2={input.s2}"
            " out={output.m}"
            " adapter1={ADPT1}"
            " adapter2={ADPT2}"
            " t=1"
        )
        

rule fastp:
    """Reconstruction using fastp"""
    input:
        s1=OUTDIR_SIM + "/{sample}_s1.fq.gz",
        s2=OUTDIR_SIM + "/{sample}_s2.fq.gz",
    output:
        m=OUTDIR_REC + "/fastp/{sample}_merged.fq.gz",
    benchmark:
        OUTDIR_BEN + "/fastp/{sample}_merged.tsv"
    shell:
        # --overlap_len_require            
        #           the minimum length to detect overlapped region of PE
        #           reads. This will affect overlap analysis based PE
        #           merge, adapter trimming and correction. 30 by
        #           default. (int [=30])
        #   -L, --disable_length_filtering       
        #           length filtering is enabled by default. If this
        #           option is specified, length filtering is disabled
        #   -l, --length_required                
        #           reads shorter than length_required will be 
        #           discarded, default is 15. (int [=15])    
        #  -w, --thread 
        #           worker thread number, default is 2 (int [=2])
        (
            "{FASTP}"
            " --merge "
            " --merged_out {output.m}"
            " --in1 {input.s1}"
            " --in2 {input.s2}"
            " --adapter_sequence {ADPT1}"
            " --adapter_sequence_r2 {ADPT2}"
            " --json /dev/null"
            " --html /dev/null"
            " --thread 1"
        )


rule SeqPrep:
    """Reconstruction using SeqPrep"""
    input:
        s1=OUTDIR_SIM + "/{sample}_s1.fq.gz",
        s2=OUTDIR_SIM + "/{sample}_s2.fq.gz",
    output:
        m=OUTDIR_REC + "/SeqPrep/{sample}_merged.fq.gz",
    benchmark:
        OUTDIR_BEN + "/SeqPrep/{sample}_merged.tsv"
    shell:
        # The output is always gziped compressed.
        # -f <first read input fastq filename>
        # -r <second read input fastq filename>
        # -s <perform merging and output the merged reads to this file>
        # -1 <first read output fastq filename>
        # -2 <second read output fastq filename>
        # -L <Minimum length of a trimmed/merged read; default = 30>
        # -A <forward read primer/adapter sequence to trim>
        # -B <reverse read primer/adapter sequence to trim>
        # -O <minimum overall base pair overlap with adapter sequence to 
        #    trim; default = 10>
        # -o <minimum overall base pair overlap to merge two reads; 
        #    default = 15>
        # -y <maximum quality score in output ((phred 33) default=']' )>
        (
            "{SEQPREP}"
            " -f {input.s1}"
            " -r {input.s2}"
            " -s {output.m}"
            " -A {ADPT1}"
            " -B {ADPT2}"
            " -1 /dev/null"
            " -2 /dev/null"
        )


# Align reads to reference genome

rule index_reference_genome:
    input:
        REF_GENOME
    output:
        REF_GENOME + ".amb",
        REF_GENOME + ".ann",
        REF_GENOME + ".bwt",
        REF_GENOME + ".pac",
        REF_GENOME + ".sa",
    shell:
        (
            "{BWA} index {input}"
        )



rule align_to_reference_genome:
    input:
        reads=OUTDIR_REC + "/{tool_name}/{sample}_merged.fq.gz",
        idx1=REF_GENOME + ".amb",
        idx2=REF_GENOME + ".ann",
        idx3=REF_GENOME + ".bwt",
        idx4=REF_GENOME + ".pac",
        idx5=REF_GENOME + ".sa",
    output:
        OUTDIR_ALI + "/{tool_name}/{sample}_sorted.bam",
    benchmark:
        OUTDIR_BEN + "/{tool_name}/{sample}_align.tsv"
    resources:
         mem_mb = 90000
    threads: 10
    shell:
        # samtools view
        # -u    Output uncompressed data and changes the default output format 
        #       to BAM. This option saves time spent and is thus preferred 
        #       when the output is piped to another samtools command. 
        # -S    Ignored for compatibility with previous samtools versions. 
        #       Previously this option was required if input was in SAM format
        (
            "{BWA} mem"
            " -t 10"
            " -R '@RG\\tID:{wildcards.sample}\\tSM:{wildcards.sample}'"
            " {REF_GENOME}"
            " {input.reads}"
            " | {samtools} sort"
            " -@ {threads}"
            " -m 8G"
            " -"
            " > {output}"
        )


rule mark_duplicates:
    """ Mark PCR duplicates"""
    input:
        OUTDIR_ALI + "/{tool_name}/{sample}_sorted.bam",
    output:
        OUTDIR_ALI + "/{tool_name}/{sample}_markdup.bam",
    params:
        OUTDIR_ALI + "/{tool_name}/{sample}_markdup.metrics.txt",
    benchmark:
        OUTDIR_BEN + "/{tool_name}/{sample}_markdup.tsv"
    resources:
        mem_mb = 16000
    shell:
        (
            "java -jar {PICARD} MarkDuplicates"
            " -I {input}"
            " -M {params}"
            " -O {output}"
        )


rule coverage:
    """Generate statistics file of the alignment"""
    input:
        OUTDIR_ALI + "/{tool_name}/{sample}_markdup.bam",
    output:
        OUTDIR_ALI + "/{tool_name}/{sample}_markdup_coverage.tsv",
    benchmark:
        OUTDIR_BEN + "/{tool_name}/{sample}_coverage.tsv"
    shell:
        ("{samtools} coverage {input} > {output}")


# Subsample alignment

rule subsample:
    input:
        OUTDIR_ALI + "/{tool_name}/{sample}_markdup.bam",
    output:
        OUTDIR_ALI + "/{tool_name}/subsample/{sample}_{fraction}_{seed}.bam",
    shell:
        # -b    output BAM
        # -s    subsample reads (given INT.FRAC option value, 0.FRAC is the 
        #       fraction of templates/read pairs to keep; INT part sets seed)
        (
            "{samtools} view"
            " -b"
            " -s {wildcards.seed}.{wildcards.fraction}"
            " {input}"
            " > {output}"
        )


rule pileupCaller:
    """ Uses pileupCaller (https://github.com/stschiff/sequenceTools) to 
    sample alleles from low coverage sequence data. Samples one read at 
    random at each site to call a pseudohaploid genotype.
    """
    input:
        OUTDIR_ALI + "/{tool_name}/subsample/{sample}_{fraction}_{seed}.bam"
    output:
        ind=OUTDIR_EIG + "/{tool_name}/{sample}_{fraction}_{seed}.ind",
        geno=OUTDIR_EIG + "/{tool_name}/{sample}_{fraction}_{seed}.geno",
    params:
        samplename="{sample}-{tool_name}-{fraction}-{seed}",
        popname="{sample}-{tool_name}-{fraction}",
        basename=OUTDIR_EIG + "/{tool_name}/{sample}_{fraction}_{seed}",
        snp=OUTDIR_EIG + "/{tool_name}/{sample}_{fraction}_{seed}.snp",
    conda:
        "envs/PCA_population_analysis.yml"
    run:
        # samtools
        # -B      disables base alignment quality recalibration. This mechanism
        #         is turned on by default and causes huge reference bias with 
        #         low coverage ancient DNA data.
        # -R      ignore RG tags (one BAM = one sample)
        # -q INT  skip alignments with mapQ smaller than INT [0]
        # -Q INT  skip bases with baseQ/BAQ smaller than INT [13]
        # -l      skip unlisted positions (chr pos) or regions (BED)
        # pileupCaller
        # --randomHaploid          
        #       This method samples one read at random at each site, and uses 
        #       the allele on that read as the one for the actual genotype. 
        #       This results in a haploid call
        # --singleStrandMode       
        #       [THIS IS CURRENTLY AN EXPERIMENTAL FEATURE]. At C/T
        #       polymorphisms, ignore reads aligning to the forward
        #       strand. At G/A polymorphisms, ignore reads aligning
        #       to the reverse strand. This should remove post-mortem
        #       damage in ancient DNA libraries prepared with the
        #       non-UDG single-stranded protocol.
        # --snpFile <FILE>
        #       an Eigenstrat-formatted SNP list file for the
        #       positions and alleles to call. All positions in the
        #       SNP file will be output, adding missing data where
        #       there is no data. Note that pileupCaller
        #       automatically checks whether alleles in the SNP file
        #       are flipped with respect to the human reference, and
        #       in those cases flips the genotypes accordingly. But
        #       it assumes that the strand-orientation of the SNPs
        #       given in the SNP list is the one in the reference
        #       genome used in the BAM file underlying the pileup
        #       input. Note that both the SNP file and the incoming
        #       pileup data have to be ordered by chromosome and
        #       position, and this is checked. The chromosome order
        #       in humans is 1-22,X,Y,MT. Chromosome can generally
        #       begin with "chr". In case of non-human data with
        #       different chromosome names, you should convert all
        #       names to numbers. They will always considered to be
        #       numerically ordered, even beyond 22. Finally, I note
        #       that for internally, X is converted to 23, Y to 24
        #       and MT to 90. This is the most widely used encoding
        #       in Eigenstrat databases for human data, so using a
        #       SNP file with that encoding will automatically be
        #       correctly aligned to pileup data with actual
        #       chromosome names X, Y and MT (or chrX, chrY and
        #       chrMT, respectively).
        shell(
            "{samtools} mpileup"
            " -R -B"
            " -q30"
            " -Q30"
            " -l {pos}"
            " -f {REF_GENOME}"
            " {input}"
            " | pileupCaller"
            " --randomHaploid"
            " --sampleNames {params.samplename}"
            " --samplePopName {params.popname}"
            " --snpFile {snp}"
            " --seed {SEED}"
            " --eigenstratOut {params.basename}"
        )
        shell("rm {params.snp}")
        shell("echo '{params.samplename} M {params.popname}' > {output.ind}")


rule combine_eigenstrat_files:
    input:
        expand(
            OUTDIR_EIG + "/{tool_name}/{sample}_{fraction}_{seed}.geno",
            tool_name=TOOLNAMES,
            sample=SAMPLES,
            seed=SUBSAMPLE_SEEDS, 
            fraction=SUBSAMPLE_FRACTIONS,
        ),
        expand(
            OUTDIR_EIG + "/{tool_name}/{sample}_{fraction}_{seed}.ind",
            tool_name=TOOLNAMES,
            sample=SAMPLES,
            seed=SUBSAMPLE_SEEDS, 
            fraction=SUBSAMPLE_FRACTIONS,
        ),
    output:
        geno=OUTDIR_EIG + "/HG002_HG005.geno",
        ind=OUTDIR_EIG + "/HG002_HG005.ind",
    run:
        shell("cat {OUTDIR_EIG}/*/*.ind > {output.ind}")
        shell("paste -d '' {OUTDIR_EIG}/*/*.geno > {output.geno}")


rule mergeit:
    input:
        INDIR + "/human_origins_genotype_dataset/data.geno",
        INDIR + "/human_origins_genotype_dataset/data.ind",
        INDIR + "/human_origins_genotype_dataset/data.snp",
        OUTDIR_EIG + "/HG002_HG005.geno",
        OUTDIR_EIG + "/HG002_HG005.ind",
        INDIR + "/smartPCA/mergeit_parameter.txt",
    output:
        geno=OUTDIR_EIG + "/HO_HG002_HG005.geno",
        ind=OUTDIR_EIG + "/HO_HG002_HG005.ind",
        snp=OUTDIR_EIG + "/HO_HG002_HG005.snp",
    conda:
        "envs/downstream_analysis.yml"
    shell:   
        ("mergeit -p {INDIR}/smartPCA/mergeit_parameter.txt")


# rule smartPCA:
#     input:
#         OUTDIR_EIG + "/HO_HG002_HG005.geno",
#         OUTDIR_EIG + "/HO_HG002_HG005.ind",
#         OUTDIR_EIG + "/HO_HG002_HG005.snp",
#         INDIR + "/smartPCA/poplists/poplist_eurasia.txt",
#         paramsfile=INDIR + "/smartPCA/smartPCA_parameter.txt",
#     output:
#         evec=OUTDIR + "/smartPCA/eurasia.evec",
#         eval=OUTDIR + "/smartPCA/eurasia.eval",
#         log=OUTDIR + "/smartPCA/eurasia.log",
#     threads:
#         22
#     conda:
#         "envs/downstream_analysis.yml"
#     shell:
#         ("smartpca -p {input.paramsfile} > {output.log}")


rule plot:
    input:
        evec=OUTDIR + "/smartPCA/eurasia.evec",
        eval=OUTDIR + "/smartPCA/eurasia.eval",
        pop=INDIR + "/smartPCA/poplists/eurasian_grouped.tsv",
        ind=OUTDIR_EIG + "/HG002_HG005.ind",
    output:
        OUTDIR_PLOT + "/pca_explained_variance_individual.png",
        OUTDIR_PLOT + "/pca_explained_variance_cumulative.png",
        expand(OUTDIR_PLOT + "/pca_all_{cov_depth}.png",
            cov_depth=["0.25X", "0.5X", "1X", "2X", "4X"]),
        expand(OUTDIR_PLOT + "/pca_zoom_{cov_depth}.png",
            cov_depth=["0.25X", "0.5X", "1X", "2X", "4X"]),
        OUTDIR_PLOT + "/pca_within_cluster_variance.png",
    shell:
        (
            "python3 {PLOT_SCRIPT}"
            " -evec {input.evec}"
            " -eval {input.eval}"
            " -pop {input.pop}"
            " -ind {input.ind}"
            " -o {OUTDIR_PLOT}"
        )